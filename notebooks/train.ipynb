{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14531/3428451221.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_df[misc_cont_cols] = scaler.transform(valid_df[misc_cont_cols])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Bucharest record min and max temperatures, adjusted according to source\n",
    "# Source: https://www.extremeweatherwatch.com/cities/bucharest/lowest-temperatures\n",
    "BUC_MIN_TEMP = -35\n",
    "BUC_MAX_TEMP = 45\n",
    "\n",
    "N_LAGS = 7\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    # Set the date as the index\n",
    "    index = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
    "    df.set_index(index, inplace=True)\n",
    "\n",
    "    # Clean rows\n",
    "    # Sea Level Pressure, gets dropped, too many 0, not enough relevant info\n",
    "    corrupted = df[df[\"Sea_Level_Pressure\"] == \"True\"]\n",
    "    df.drop(index=corrupted.index, inplace=True)\n",
    "    df.drop(\"Sea_Level_Pressure\", axis=1, inplace=True)\n",
    "\n",
    "    # Humidity Average, 11 rows with NaN, can drop them\n",
    "    corrupted = df[df[\"Humidity_Avg\"].isna()]\n",
    "    df.drop(index=corrupted.index, inplace=True)\n",
    "\n",
    "    # Precipitation Total, fill Nan with 0\n",
    "    df[\"Precipitation_Total\"].fillna(\"0\", inplace=True)\n",
    "\n",
    "    # Visibility Average, gets dropped, too many NaN values > 10%\n",
    "    df.drop(\"Visibility_Avg\", axis=1, inplace=True)\n",
    "\n",
    "    # Wind Max, contains mostly NaN values, can drop\n",
    "    # We have Wind Sustained Max which is clean\n",
    "    df.drop(\"Wind_Max\", axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_temp_data(df):\n",
    "    # Create new dataframe\n",
    "    scaled = df.copy(deep=True)\n",
    "\n",
    "    # Scale with record min and max\n",
    "    temp_scaler = MinMaxScaler()\n",
    "    temp_scaler.fit(np.array((BUC_MIN_TEMP, BUC_MAX_TEMP)).reshape(-1, 1))\n",
    "\n",
    "    cols = temp_cols\n",
    "    temp_data = np.array(df[cols]).T\n",
    "    scaled = df.copy(deep=True)\n",
    "    temp_scaled = [temp_scaler.transform(X.reshape(-1, 1)) for X in temp_data]\n",
    "    for idx, col in enumerate(cols):\n",
    "        scaled[col] = temp_scaled[idx]\n",
    "    return scaled, temp_scaler\n",
    "\n",
    "\n",
    "def normalize_data(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    cols = misc_cont_cols\n",
    "    df[cols] = scaler.fit_transform(df[cols])\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "def build_set(ds, lags=10):\n",
    "    train = []\n",
    "    true = []\n",
    "    for idx in range(len(ds) - lags):\n",
    "        current = ds[idx : idx + lags]\n",
    "        pred = ds[idx + lags][temp_avg_idx]\n",
    "        train.append(current)\n",
    "        true.append(pred)\n",
    "\n",
    "    train = torch.cat([t for t in train]).reshape(-1, lags, ds.shape[1])\n",
    "    true = torch.tensor(true).reshape(-1, 1)\n",
    "    return train, true\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = clean_data(df)\n",
    "\n",
    "# Boolean columns\n",
    "cat_cols = [col for col in df.columns if col.startswith(\"Is\")]\n",
    "# Continous columns\n",
    "cont_cols = list(\n",
    "    set(df.columns) - set(cat_cols) - set([\"Year\", \"Month\", \"Day\"])\n",
    ")\n",
    "# Temperature columns\n",
    "temp_cols = [col for col in cont_cols if col.startswith(\"Temperature\")]\n",
    "# Miscellaneous continuous columns -> Humidity, Precipitation, Wind\n",
    "misc_cont_cols = list(set(cont_cols) - set(temp_cols))\n",
    "\n",
    "# Set correct datatypes\n",
    "df[cont_cols] = df[cont_cols].astype(\"float\")\n",
    "\n",
    "# Scale temperatures on the whole dataset\n",
    "scaled, temp_scaler = normalize_temp_data(df)\n",
    "\n",
    "valid_start = \"2022-01-01\"\n",
    "train_df = scaled[:valid_start][:-1]\n",
    "valid_df = scaled[valid_start:]\n",
    "\n",
    "# Scale the rest of the continous columns\n",
    "train_df, scaler = normalize_data(train_df)\n",
    "valid_df[misc_cont_cols] = scaler.transform(valid_df[misc_cont_cols])\n",
    "\n",
    "# Convert to tensors\n",
    "train_cont = torch.tensor(np.stack([train_df[cont_cols]]), dtype=torch.float)\n",
    "train_cat = torch.tensor(np.stack([train_df[cat_cols]]), dtype=torch.float)\n",
    "valid_cont = torch.tensor(np.stack([valid_df[cont_cols]]), dtype=torch.float)\n",
    "valid_cat = torch.tensor(np.stack([valid_df[cat_cols]]), dtype=torch.float)\n",
    "\n",
    "# Create a train and valid dataset\n",
    "train_ds = torch.cat((train_cont, train_cat), dim=2).squeeze()\n",
    "valid_ds = torch.cat((valid_cont, valid_cat), dim=2).squeeze()\n",
    "\n",
    "temp_avg_idx = cont_cols.index(\"Temperature_Avg\")\n",
    "\n",
    "x_train, y_train = build_set(train_ds, N_LAGS)\n",
    "\n",
    "# Add the last N_LAGS elements to valid_ds to ensure continuity\n",
    "x_valid, y_valid = build_set(torch.cat((train_ds[-N_LAGS:], valid_ds)), N_LAGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6216, 0.3318, 0.4750, 0.5325, 0.3419, 0.0000, 0.6150, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.9459, 0.3079, 0.4250, 0.4475, 0.4791, 0.0000, 0.5725, 1.0000, 1.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.9865, 0.3662, 0.4250, 0.4363, 0.4349, 0.0195, 0.4400, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0867, 0.4250, 0.4338, 0.1465, 0.0332, 0.4412, 1.0000, 1.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.9865, 0.1136, 0.4162, 0.4275, 0.1977, 0.0000, 0.4375, 1.0000, 1.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [1.0000, 0.1390, 0.4275, 0.4475, 0.2070, 0.0371, 0.4638, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.2242, 0.4500, 0.4737, 0.2767, 0.0039, 0.5088, 1.0000, 0.0000,\n",
       "         0.0000, 1.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[-N_LAGS:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9324, 0.0867, 0.4625, 0.5238, 0.1372, 0.0019, 0.6000, 1.0000, 0.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.8514, 0.1659, 0.4350, 0.5075, 0.1605, 0.0000, 0.5625, 0.0000, 0.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.8514, 0.2242, 0.4650, 0.5225, 0.2628, 0.0000, 0.5813, 0.0000, 0.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.7027, 0.1659, 0.4663, 0.5200, 0.2279, 0.0000, 0.6012, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7838, 0.2242, 0.4750, 0.5288, 0.2535, 0.0000, 0.6263, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7297, 0.2242, 0.4500, 0.5312, 0.2535, 0.0000, 0.6388, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7568, 0.3318, 0.4563, 0.4750, 0.3140, 0.0000, 0.5638, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[:N_LAGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6892, 0.1136, 0.3500, 0.3862, 0.1093, 0.0000, 0.4375, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [0.6757, 0.3318, 0.3663, 0.4512, 0.3698, 0.0000, 0.5400, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [0.6216, 0.3318, 0.4750, 0.5325, 0.3419, 0.0000, 0.6150, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [0.9459, 0.3079, 0.4250, 0.4475, 0.4791, 0.0000, 0.5725, 1.0000,\n",
       "          1.0000, 0.0000, 0.0000],\n",
       "         [0.9865, 0.3662, 0.4250, 0.4363, 0.4349, 0.0195, 0.4400, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0867, 0.4250, 0.4338, 0.1465, 0.0332, 0.4412, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [0.9865, 0.1136, 0.4162, 0.4275, 0.1977, 0.0000, 0.4375, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.6757, 0.3318, 0.3663, 0.4512, 0.3698, 0.0000, 0.5400, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [0.6216, 0.3318, 0.4750, 0.5325, 0.3419, 0.0000, 0.6150, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [0.9459, 0.3079, 0.4250, 0.4475, 0.4791, 0.0000, 0.5725, 1.0000,\n",
       "          1.0000, 0.0000, 0.0000],\n",
       "         [0.9865, 0.3662, 0.4250, 0.4363, 0.4349, 0.0195, 0.4400, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0867, 0.4250, 0.4338, 0.1465, 0.0332, 0.4412, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [0.9865, 0.1136, 0.4162, 0.4275, 0.1977, 0.0000, 0.4375, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [1.0000, 0.1390, 0.4275, 0.4475, 0.2070, 0.0371, 0.4638, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4475],\n",
       "        [0.4737]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9324, 0.0867, 0.4625, 0.5238, 0.1372, 0.0019, 0.6000, 1.0000, 0.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.8514, 0.1659, 0.4350, 0.5075, 0.1605, 0.0000, 0.5625, 0.0000, 0.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.8514, 0.2242, 0.4650, 0.5225, 0.2628, 0.0000, 0.5813, 0.0000, 0.0000,\n",
       "         0.0000, 1.0000],\n",
       "        [0.7027, 0.1659, 0.4663, 0.5200, 0.2279, 0.0000, 0.6012, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7838, 0.2242, 0.4750, 0.5288, 0.2535, 0.0000, 0.6263, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7297, 0.2242, 0.4500, 0.5312, 0.2535, 0.0000, 0.6388, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7568, 0.3318, 0.4563, 0.4750, 0.3140, 0.0000, 0.5638, 1.0000, 0.0000,\n",
       "         0.0000, 0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[:N_LAGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6216, 0.3318, 0.4750, 0.5325, 0.3419, 0.0000, 0.6150, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [0.9459, 0.3079, 0.4250, 0.4475, 0.4791, 0.0000, 0.5725, 1.0000,\n",
       "          1.0000, 0.0000, 0.0000],\n",
       "         [0.9865, 0.3662, 0.4250, 0.4363, 0.4349, 0.0195, 0.4400, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0867, 0.4250, 0.4338, 0.1465, 0.0332, 0.4412, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [0.9865, 0.1136, 0.4162, 0.4275, 0.1977, 0.0000, 0.4375, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [1.0000, 0.1390, 0.4275, 0.4475, 0.2070, 0.0371, 0.4638, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.2242, 0.4500, 0.4737, 0.2767, 0.0039, 0.5088, 1.0000,\n",
       "          0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.9459, 0.3079, 0.4250, 0.4475, 0.4791, 0.0000, 0.5725, 1.0000,\n",
       "          1.0000, 0.0000, 0.0000],\n",
       "         [0.9865, 0.3662, 0.4250, 0.4363, 0.4349, 0.0195, 0.4400, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0867, 0.4250, 0.4338, 0.1465, 0.0332, 0.4412, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [0.9865, 0.1136, 0.4162, 0.4275, 0.1977, 0.0000, 0.4375, 1.0000,\n",
       "          1.0000, 0.0000, 1.0000],\n",
       "         [1.0000, 0.1390, 0.4275, 0.4475, 0.2070, 0.0371, 0.4638, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.2242, 0.4500, 0.4737, 0.2767, 0.0039, 0.5088, 1.0000,\n",
       "          0.0000, 0.0000, 1.0000],\n",
       "         [0.9324, 0.0867, 0.4625, 0.5238, 0.1372, 0.0019, 0.6000, 1.0000,\n",
       "          0.0000, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5238],\n",
       "        [0.5075]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1788, 7, 11])\n",
      "torch.Size([361, 7, 11])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2925])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "NUM_LAYERS = 3\n",
    "HIDDEN_SIZE = 128\n",
    "\n",
    "lstm = nn.LSTM(input_size=train_ds.shape[1], hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)\n",
    "hidden = (\n",
    "    torch.zeros(NUM_LAYERS, HIDDEN_SIZE),\n",
    "    torch.zeros(NUM_LAYERS, HIDDEN_SIZE),\n",
    ")\n",
    "\n",
    "out, hidden = lstm(x_train[0], hidden)\n",
    "\n",
    "dropout = nn.Dropout(0.5)\n",
    "\n",
    "out = dropout(out)\n",
    "\n",
    "fc = nn.Linear(in_features=HIDDEN_SIZE, out_features=1)\n",
    "\n",
    "out = fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0185],\n",
       "        [-0.0359],\n",
       "        [-0.0142],\n",
       "        [-0.0674],\n",
       "        [-0.0486],\n",
       "        [-0.0361],\n",
       "        [-0.0329]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=4, output_size=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, X, hidden):\n",
    "        out, hidden = self.lstm(X, hidden)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        # Only care about last prediction\n",
    "        return out[-1], hidden\n",
    "\n",
    "    def initialize_hidden(self):\n",
    "        hidden = (\n",
    "            torch.zeros(self.num_layers, self.hidden_size).to(device),\n",
    "            torch.zeros(self.num_layers, self.hidden_size).to(device),\n",
    "        )\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLSTM(\n",
       "  (lstm): LSTM(11, 128, num_layers=4, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyLSTM(input_size=train_ds.shape[1]).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874944"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 11])\n",
      "5632\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512, 128])\n",
      "65536\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([512])\n",
      "512\n",
      "torch.Size([1, 128])\n",
      "128\n",
      "torch.Size([1])\n",
      "1\n",
      "---------\n",
      "Number of parameters: 468609\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for p in model.parameters():\n",
    "    print(p.shape)\n",
    "    if p.requires_grad:\n",
    "        print(p.numel())\n",
    "        count += p.numel()\n",
    "print('---------\\nNumber of parameters:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden = model.initialize_hidden()\n",
    "# out, hidden = model.forward(x_train[0], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0185],\n",
       "        [-0.0359],\n",
       "        [-0.0142],\n",
       "        [-0.0674],\n",
       "        [-0.0486],\n",
       "        [-0.0361],\n",
       "        [-0.0329]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0] // 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6757, 0.1659, 0.3625, 0.4125, 0.2465, 0.0000, 0.5000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6081, 0.2526, 0.3625, 0.4175, 0.2419, 0.0000, 0.5163, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6081, 0.1659, 0.3500, 0.4212, 0.1163, 0.0000, 0.5025, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6622, 0.2242, 0.3462, 0.4125, 0.2116, 0.0000, 0.4950, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6892, 0.5590, 0.4250, 0.4525, 0.2070, 0.0000, 0.4888, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9054, 0.5262, 0.3125, 0.3875, 0.4047, 0.0312, 0.4675, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8649, 0.2003, 0.2875, 0.3150, 0.2372, 0.0078, 0.3475, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000]])\n",
      "tensor([0.2925])\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(x_train, y_train):\n",
    "    break\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/horia/master_siva/an2_sem1/ic3/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([7, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10833178460597992"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(out, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {0: ['ceva']})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "loss = defaultdict(list)\n",
    "\n",
    "loss[0].append('ceva')\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {0: ['ceva'], 5: ['da']})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[5].append('da')\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "l = len(str(n))\n",
    "print(f\"{n:{l}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_model(model, train_valid: tuple, criterion, optimizer, epochs=50):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss = defaultdict(list)\n",
    "    valid_loss = defaultdict(list)\n",
    "\n",
    "    x_train, y_train, x_valid, y_valid = train_valid\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        hidden = model.initialize_hidden()\n",
    "        sample = 0\n",
    "        for X, y_true in zip(x_train, y_train):\n",
    "            sample += 1\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            # Reset hidden state\n",
    "            hidden = tuple([state.data for state in hidden])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, hidden = model.forward(X, hidden)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if sample % 300 == 0:\n",
    "                train_loss[epoch].append(loss.item())\n",
    "\n",
    "                val_hidden = model.initialize_hidden()\n",
    "\n",
    "                total_val_loss = 0\n",
    "\n",
    "                model.eval()\n",
    "                for X_val, y_val_true in zip(x_valid, y_valid):\n",
    "                    X_val = X_val.to(device)\n",
    "                    y_val_true = y_val_true.to(device)\n",
    "\n",
    "                    val_hidden = tuple([state.data for state in val_hidden])\n",
    "\n",
    "                    y_val_pred, val_hidden = model.forward(X_val, val_hidden)\n",
    "                    val_loss = criterion(y_val_pred, y_val_true)\n",
    "\n",
    "                    total_val_loss += val_loss.item()\n",
    "\n",
    "                avg_loss = total_val_loss / len(x_valid)\n",
    "                valid_loss[epoch].append(avg_loss)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                print(f\"Epoch: {epoch:{len(str(epochs))}} Sample: {sample:{len(str(x_train.shape[0]))}} Train Loss: {loss.item():3.8f} Avg Valid Loss: {avg_loss}\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Duration = {end - start} seconds\")\n",
    "\n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Sample:  300 Train Loss: 0.00013301 Avg Valid Loss: 0.019230159879201455\n",
      "Epoch:  0 Sample:  600 Train Loss: 0.00008512 Avg Valid Loss: 0.02301890809327961\n",
      "Epoch:  0 Sample:  900 Train Loss: 0.01347268 Avg Valid Loss: 0.020197028011631677\n",
      "Epoch:  0 Sample: 1200 Train Loss: 0.00309737 Avg Valid Loss: 0.017980020798573238\n",
      "Epoch:  0 Sample: 1500 Train Loss: 0.00369699 Avg Valid Loss: 0.022369278002289005\n",
      "Epoch:  1 Sample:  300 Train Loss: 0.00875286 Avg Valid Loss: 0.012980563746236976\n",
      "Epoch:  1 Sample:  600 Train Loss: 0.00379252 Avg Valid Loss: 0.03904289389283848\n",
      "Epoch:  1 Sample:  900 Train Loss: 0.00425653 Avg Valid Loss: 0.02138661488850336\n",
      "Epoch:  1 Sample: 1200 Train Loss: 0.00309960 Avg Valid Loss: 0.01909612338741273\n",
      "Epoch:  1 Sample: 1500 Train Loss: 0.00075625 Avg Valid Loss: 0.023136312700647216\n",
      "Epoch:  2 Sample:  300 Train Loss: 0.00057610 Avg Valid Loss: 0.01402631218137083\n",
      "Epoch:  2 Sample:  600 Train Loss: 0.00040095 Avg Valid Loss: 0.035322411872887156\n",
      "Epoch:  2 Sample:  900 Train Loss: 0.00180335 Avg Valid Loss: 0.020064723767851473\n",
      "Epoch:  2 Sample: 1200 Train Loss: 0.00020972 Avg Valid Loss: 0.01648360158176504\n",
      "Epoch:  2 Sample: 1500 Train Loss: 0.00050930 Avg Valid Loss: 0.02366475838760558\n",
      "Epoch:  3 Sample:  300 Train Loss: 0.00006204 Avg Valid Loss: 0.013490150598269373\n",
      "Epoch:  3 Sample:  600 Train Loss: 0.00277062 Avg Valid Loss: 0.03133550160476012\n",
      "Epoch:  3 Sample:  900 Train Loss: 0.00002651 Avg Valid Loss: 0.0184403411306485\n",
      "Epoch:  3 Sample: 1200 Train Loss: 0.00001741 Avg Valid Loss: 0.016901127299275464\n",
      "Epoch:  3 Sample: 1500 Train Loss: 0.00007593 Avg Valid Loss: 0.0261722959739129\n",
      "Epoch:  4 Sample:  300 Train Loss: 0.00003132 Avg Valid Loss: 0.013621627243404802\n",
      "Epoch:  4 Sample:  600 Train Loss: 0.00026256 Avg Valid Loss: 0.03301699852482976\n",
      "Epoch:  4 Sample:  900 Train Loss: 0.00058697 Avg Valid Loss: 0.019575923766682532\n",
      "Epoch:  4 Sample: 1200 Train Loss: 0.00013478 Avg Valid Loss: 0.01475562249362282\n",
      "Epoch:  4 Sample: 1500 Train Loss: 0.00036063 Avg Valid Loss: 0.02647553823919522\n",
      "Epoch:  5 Sample:  300 Train Loss: 0.00003960 Avg Valid Loss: 0.013209933455215386\n",
      "Epoch:  5 Sample:  600 Train Loss: 0.00114177 Avg Valid Loss: 0.02980989704695761\n",
      "Epoch:  5 Sample:  900 Train Loss: 0.00574075 Avg Valid Loss: 0.017126234787179676\n",
      "Epoch:  5 Sample: 1200 Train Loss: 0.00092842 Avg Valid Loss: 0.013500430504056764\n",
      "Epoch:  5 Sample: 1500 Train Loss: 0.00048801 Avg Valid Loss: 0.025665469803394316\n",
      "Epoch:  6 Sample:  300 Train Loss: 0.00016165 Avg Valid Loss: 0.012668682854306758\n",
      "Epoch:  6 Sample:  600 Train Loss: 0.00078274 Avg Valid Loss: 0.033576435286030736\n",
      "Epoch:  6 Sample:  900 Train Loss: 0.00093516 Avg Valid Loss: 0.01685434105683645\n",
      "Epoch:  6 Sample: 1200 Train Loss: 0.00433380 Avg Valid Loss: 0.012325697160666402\n",
      "Epoch:  6 Sample: 1500 Train Loss: 0.00006026 Avg Valid Loss: 0.023426797537638835\n",
      "Epoch:  7 Sample:  300 Train Loss: 0.00130350 Avg Valid Loss: 0.01231304648102869\n",
      "Epoch:  7 Sample:  600 Train Loss: 0.00070020 Avg Valid Loss: 0.029538892559850042\n",
      "Epoch:  7 Sample:  900 Train Loss: 0.00209020 Avg Valid Loss: 0.021300209626024\n",
      "Epoch:  7 Sample: 1200 Train Loss: 0.00315487 Avg Valid Loss: 0.01233148423040073\n",
      "Epoch:  7 Sample: 1500 Train Loss: 0.00054257 Avg Valid Loss: 0.023444668366517967\n",
      "Epoch:  8 Sample:  300 Train Loss: 0.00148971 Avg Valid Loss: 0.012313138882811915\n",
      "Epoch:  8 Sample:  600 Train Loss: 0.00055578 Avg Valid Loss: 0.03104348861070365\n",
      "Epoch:  8 Sample:  900 Train Loss: 0.00000425 Avg Valid Loss: 0.02398422731168371\n",
      "Epoch:  8 Sample: 1200 Train Loss: 0.00480937 Avg Valid Loss: 0.012344351502521687\n",
      "Epoch:  8 Sample: 1500 Train Loss: 0.00000107 Avg Valid Loss: 0.02384857998941181\n",
      "Epoch:  9 Sample:  300 Train Loss: 0.00096309 Avg Valid Loss: 0.012381788553722795\n",
      "Epoch:  9 Sample:  600 Train Loss: 0.00347586 Avg Valid Loss: 0.035151141929158795\n",
      "Epoch:  9 Sample:  900 Train Loss: 0.00137943 Avg Valid Loss: 0.021182849025071424\n",
      "Epoch:  9 Sample: 1200 Train Loss: 0.00464150 Avg Valid Loss: 0.012331827148136914\n",
      "Epoch:  9 Sample: 1500 Train Loss: 0.00000358 Avg Valid Loss: 0.02716783206236268\n",
      "Duration = 50.891584157943726 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = train_model(model, (x_train, y_train, x_valid, y_valid), criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tloss = [np.array(v).sum() / len(v) for k,v in train_loss.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vloss = [np.array(v).sum() / len(v) for k,v in valid_loss.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f89125e75b0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tloss)\n",
    "plt.plot(vloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
